{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhikaa2/bebas/blob/main/untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUgGpW4ee0St",
        "outputId": "54cb1de0-edc9-4422-a847-fd7b0297b0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def read_imdb_data(data_dir):\n",
        "    data = {}\n",
        "    labels = {}\n",
        "    for data_type in ['train', 'test']:\n",
        "        data[data_type] = {}\n",
        "        labels[data_type] = {}\n",
        "        for sentiment in ['pos', 'neg']:\n",
        "            data[data_type][sentiment] = []\n",
        "            labels[data_type][sentiment] = []\n",
        "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
        "            files = glob.glob(path)\n",
        "            for f in files:\n",
        "                with open(f, encoding='utf-8') as review:\n",
        "                    data[data_type][sentiment].append(review.read())\n",
        "                    labels[data_type][sentiment].append(sentiment)\n",
        "    return data, labels\n",
        "\n",
        "data, labels = read_imdb_data('/content/drive/MyDrive/data')\n",
        "print(\"IMDb reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
        "    len(data['train']['pos']), len(data['train']['neg']),\n",
        "    len(data['test']['pos']), len(data['test']['neg'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUa1oYEgohA",
        "outputId": "e46fda14-2797-439c-9ec2-e0ad5baa8b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMDb reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Review positif:\\n\")\n",
        "print(data['train']['pos'][0])\n",
        "\n",
        "print(\"\\nReview negatif:\\n\")\n",
        "print(data['train']['neg'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NGIrzI5lzIp",
        "outputId": "77383abd-8e65-4379-bb8d-08ee37bc9d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review positif:\n",
            "\n",
            "I read so many comments that I, too, shared about remembering this movie and wanting so badly to see it again but I didn't know the name of the movie. Thankfully, because of doing a search and finding the title on this site, I read the comments left here and realized that this was the movie I remembered. I then did a search and did find the movie and was so thrilled to be able to watch the movie once more 40 years later. Because of this site and your comments, you helped me and so I want to thank all of you. I want to share how I was able to find this movie for all of you who were looking for a copy as well. It was on the VHS version of Wonderful World of Disney's \"Call it Courage\" which contained 2 movies, the second one being \"The Legend of the Boy and the Eagle.\" It touched me now as much as it did 40 years ago and now I own my own copy of it. I think it is only available on VHS. I found it on ebay and I have seen several copies of it there. Enjoy it, I know I did!<br /><br />It is a wonderful story about the love of a boy and the eagle he took care of. When it was time to sacrifice the eagle, the boy set the eagle free because he couldn't allow it to be killed. After the boy was forced to leave the tribe for punishment after freeing the eagle, the eagle, too, saved the boy's life and more than that, taught him how to survive. The closeness that the boy and the eagle shared in the wilderness was so moving and the filming was really remarkable. What a wonderful era this was. I have never seen anything come even close to this movie!\n",
            "\n",
            "Review negatif:\n",
            "\n",
            "Kojak meets the mafia. Telly Savales is one of those guys from the past that seems pretty forgettable. I never thought that his show was all that great. This is his one dimensional characterization of a crime boss, with very predictable results. If you take the car chases and the general rambling out, there isn't much plot development or action. I find mafia movies to be dull because I have no respect or interest in common criminals and their actions. Hollywood, and in this case, the Italian cinema, treat these guys as heroes. I saw the film and in a few days I won't remember much about it. Lots of shooting, innocent bystanders dying, betrayal, and that sick loyalty. The film is photographed pretty well and the acting is decent. But the dubbing is so bad (due to voices that just couldn't come out of those bodies), that I almost started looking for Godzilla approaching the bay.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = data['train']['pos'] + data['train']['neg']\n",
        "train_labels = [1]*len(data['train']['pos']) + [0]*len(data['train']['neg'])\n",
        "\n",
        "test_texts = data['test']['pos'] + data['test']['neg']\n",
        "test_labels = [1]*len(data['test']['pos']) + [0]*len(data['test']['neg'])\n"
      ],
      "metadata": {
        "id": "0c2T87qRgu22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 10000\n",
        "max_length = 500\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train_texts)\n",
        "X_test = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "y_train = train_labels\n",
        "y_test = test_labels\n"
      ],
      "metadata": {
        "id": "ovkz5SVsl26w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "aKPBwHtGl4ER",
        "outputId": "6ecb4a48-2ecc-426a-fd75-6a4fc32429db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV9ymqPrl7Ei",
        "outputId": "d48b5d7e-9acc-4291-e100-556a7596bf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.5006 - loss: 0.6936 - val_accuracy: 0.5002 - val_loss: 0.6933\n",
            "Epoch 2/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - accuracy: 0.5091 - loss: 0.6921 - val_accuracy: 0.5039 - val_loss: 0.6951\n",
            "Epoch 3/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.5172 - loss: 0.6805 - val_accuracy: 0.4990 - val_loss: 0.7045\n",
            "Epoch 4/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.5283 - loss: 0.6552 - val_accuracy: 0.4989 - val_loss: 0.7229\n",
            "Epoch 5/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.5374 - loss: 0.6466 - val_accuracy: 0.4997 - val_loss: 0.7369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi test: {acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJWn_WQl8qS",
        "outputId": "b93dc89c-1a3a-467f-b07c-51b0fff13fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8138 - loss: 0.7136\n",
            "Akurasi test: 49.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    pred = model.predict(padded)[0][0]\n",
        "    label = \"Positif\" if pred > 0.5 else \"Negatif\"\n",
        "    print(f\"Prediksi: {label} ({pred:.2f})\")\n",
        "\n",
        "predict_review(\"This movie was amazing! I loved the acting and the story.\")\n",
        "predict_review(\"Terrible movie. Waste of time and money.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGbPGC4cmD8y",
        "outputId": "414f328e-f434-4353-d433-2d4d73617871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "Prediksi: Positif (0.52)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Prediksi: Positif (0.52)\n"
          ]
        }
      ]
    }
  ]
}